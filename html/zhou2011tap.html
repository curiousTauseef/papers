<!DOCTYPE html>
<html>
<head>
  <title>Papers</title>
  <link href='../css/style.css' rel='stylesheet'>
  <meta name=viewport content="width=device-width, initial-scale=1">
</head>

<body>
  <div id=header>
    <a href="../">Papers</a>
  </div>
  <div id="container">
<h1 id="tap-time-aware-provenance-for-distributed-systems-2011"><a href="https://scholar.google.com/scholar?cluster=7431618492252098377">TAP: Time-aware Provenance for Distributed Systems (2011)</a></h1>
<p><strong>Network provenance</strong>---provenance, but over the network---allows network administrators to query the <em>history</em> and <em>derivation</em> of a tuple generated by some distributed system written in NDLog. Applying provenance to distributed systems has a number of challenges:</p>
<ol style="list-style-type: decimal">
<li><strong>Transient and inconsistent state.</strong> When a tuple is inserted or deleted from a declarative network, the provenance information has to be updated. This update is orchestrated by multiple nodes over the network, so it can take a while. Provenance queries that occur during the update may see inconsistent results.</li>
<li><strong>Explanations for state changes.</strong> Traditional provenance can answer why a particular query exists right now, but it can't answer why the tuple has appeared, disappeared, or changed.</li>
<li><strong>Security without trusted nodes.</strong> It would be nice if we could answer provenance queries even if some nodes in the system have been compromised by an attacker.</li>
</ol>
<h2 id="time-aware-provenance">Time-aware Provenance</h2>
<p>TAP models provenance as a graph which is stored in a collection of horizontally partitioned relations, similar to <em>Efficient Querying and Maintenance of Network Provenance at Internet-Scale</em>. The difference is in the vertices and edges.</p>
<h3 id="vertices">Vertices</h3>
<p>Each TAP vertex is one of four forms:</p>
<ul>
<li><code>Insert(n, $\tau$, t)</code> represents that tuple $\tau$ was created at node <code>n</code> at time <code>t</code>.</li>
<li><code>Delete(n, $\tau$, t)</code> represents that tuple $\tau$ was deleted at node <code>n</code> at time <code>t</code>.</li>
<li><code>Derive(n, $\tau$, R, t)</code> represents that tuple $\tau$ was derived using rule <code>R</code> at node <code>n</code> at time <code>t</code>.</li>
<li><code>Underive(n, $\tau$, R, t)</code> represents that tuple $\tau$ was underived using rule <code>R</code> at node <code>n</code> at time <code>t</code>.</li>
</ul>
<h3 id="edges">Edges</h3>
<p>Edges in a TAP provenance graph represent dataflow just like they do in traditional provenance graphs. There are also special <strong>update edges</strong> that capture non-dataflow changes. For example, imagine the rule</p>
<pre><code>foo(min&lt;A&gt;) :- bar(A)</code></pre>
<p>If a new entry <code>bar(B)</code> is added which is smaller than the existing minimum <code>bar(A)</code>, then the <code>bar(A)</code> entry is removed. This removal cannot be captured by a traditional dataflow edge, but it can be captured by an update edge.</p>
<h3 id="derivations">Derivations</h3>
<p>As with network provenance, NDLog programs can be rewritten to maintain provenance information at runtime.</p>
<h2 id="provenance-maintenance">Provenance Maintenance</h2>
<p>There are three ways to physically store provenance information over time (in addition to the naive approach of copying the provenance information in its entirety for every timestep).</p>
<ol style="list-style-type: decimal">
<li><strong>Provenance deltas.</strong> We can store provenance deltas over time. This reduces the storage overhead but increases the cost of querying provenance.</li>
<li><strong>Per-node input logs.</strong> If our programs are deterministic, we can log the inputs to a program and recreate the provenance information on the fly.</li>
<li><strong>System input logs.</strong> We can record the base tuples of the entire system and replay the entire system on the fly. We can also checkpoint to avoid re-doing massive amounts of work.</li>
</ol>
<p>There are a couple of factors which influence which storage format is best:</p>
<ul>
<li><strong>Querying frequency.</strong> If provenance queries are rare, then storing per-node input logs reduces the amount of stored data at the cost of more expensive queries. On the other hand, if provenance is queried often, provenance deltas is likely a good fit.</li>
<li><strong>System runtime.</strong> If programs run for a finite amount of time (e.g. a MapReduce program), then keeping system input logs is feasible.</li>
<li><strong>Local derivations.</strong> If programs perform a lot of computation but not a lot of communication, then per-node input logs can greatly reduce the amount of tuples that have to be stored.</li>
</ul>
<h2 id="provenance-querying">Provenance Querying</h2>
<p>The authors are working on a query language called <strong>TapQL</strong> (inspired by ProQL) that allows people to concisely query provenance. TapQL queries are evaluated hierarchically with three layers:</p>
<ol style="list-style-type: decimal">
<li><strong>Macroqueries.</strong> TapQL queries can ask for the provenance of more than a single tuple. A macroquery iterates over all candidate queries that match the TapQL query and issues microqueries for each.</li>
<li><strong>Microqueries.</strong> A microquery recursively collates provenance by walking the provenance information relations.</li>
<li><strong>Vertex queries.</strong> Vertex queries return the vertices and edges incident to a given vertex.</li>
</ol>
<p>We can perform a couple of query optimizations:</p>
<ul>
<li>As with network provenance, we can cache.</li>
<li>As with network provenance, we can return from threshold queries early.</li>
<li>We can enable caching and issue microqueries serially to amplify the benefits of caching.</li>
<li>We can perform traditional DBMS optimizations at the macroquery level to decide the order in which we issue microqueries.</li>
</ul>
<h2 id="secure-provenance-querying">Secure Provenance Querying</h2>
<p>It's future work to implement TAP in such a way that provenance can be queried even when some nodes have been compromised.</p>
<h2 id="commentary">Commentary</h2>
<ul>
<li><p>In Section 3, the paper makes the following claim. I don't understand how TAP remembers dependencies between tuples that existed at some point in the past. The paper never gave an example showing how a tuple remembers derivations from tuples in the past. Moreover, I don't understand how that helps prevent inconsistent queries that arise because of &quot;transient state&quot;.</p>
<blockquote>
<p>TAP also remembers dependencies between tuples that existed <em>at some point in the past</em>, which enables TAP to provide consistent answers to provenance queries even while the system is in a transient state.</p>
</blockquote></li>
<li>Figure 2 shows a traditional provenance graph and the corresponding TAP provenance graph. The two are pretty much identical except for the update edge and <code>Delete(c,minCost(@c,a,5),t3)</code> vertex. I'm confused how the new vertices provide anything new.</li>
<li><p>Section 4 describes that because TAP provenance has an additional time field, we have to be clever about how we store provenance information in order to avoid storing a huge amount of data. Again, it's not clear to me why the time field increases the storage overhead.</p></li>
</ul>
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
  </div>

  <script type="text/javascript" src="../js/mathjax_config.js"></script>
	<script>
		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

		ga('create', 'UA-90310997-2', 'auto');
		ga('send', 'pageview');
	</script>
</body>
</html>
