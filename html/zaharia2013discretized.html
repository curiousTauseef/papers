<!DOCTYPE html>
<html>
<head>
  <title>Papers</title>
  <link href='../css/style.css' rel='stylesheet'>
  <meta name=viewport content="width=device-width, initial-scale=1">
</head>

<body>
  <div id=header>
    <a href="../">Papers</a>
  </div>
  <div id="container">
<h2 id="discretized-streams-fault-tolerant-streaming-computation-at-scale-2013"><a href="https://scholar.google.com/scholar?cluster=4915408824809554257&amp;hl=en&amp;as_sdt=0,5">Discretized Streams: Fault-Tolerant Streaming Computation at Scale (2013)</a></h2>
<p><strong>Summary.</strong> Many big data applications necessitate streaming (aka real-time, interactive, or low-latency) data processing. For example</p>
<ul>
<li>a social network like Facebook may want to determine trending topics,</li>
<li>a site like Twitter may want to detect recent spam, or</li>
<li>a service operator may want to continuously monitor logs for failures.</li>
</ul>
<p>There are many streaming data processing systems out there (e.g. Storm, TimeStream, MapReduce Online, S4) and most are based on the <em>continuous operator model</em>. In this model, computation is modelled as a network of stateful operators that receive data from an upstream operator, update their internal state, and send data to downstream operators. The continuous operator model typically employs one of two recovery mechanisms.</p>
<ol style="list-style-type: decimal">
<li><em>Hot replication.</em> Operators are replicated and data is sent to every one of the replicas. Synchronization between replicas can ensure they produce equivalent results. Replication has reasonably fast recovery, but it doubles deployment cost (at least) and operator synchronization can slow down processing.</li>
<li><em>Upstream backup.</em> Operators buffer their outputs until downstream consumers checkpoint. When a downstream operator fails, a new operator is launched and its buffered inputs are sent from the upstream backup. Upstream backup doesn't greatly increase deployment cost, but recovery can be slow.</li>
</ol>
<p>In this paper, Zaharia et al. introduce a new stream processing model, <em>discretized streams</em> (D-Streams), that recovers quickly, handles stragglers, scales to hundreds of nodes, and aims to support latencies of 0.5 - 2 seconds. In this model, streams are divided into <em>stateless, determinstic batch computations on small time intervals</em>. Determinism and lineage tracking allow for parallel recovery. Moreover, D-Streams are implemented in Spark Streaming allowing a unified interface between batch and streaming computation: something of great practical value.</p>
<p>In the discretized streams model, all the data for a given time interval is collected into an RDD, tasks then operate on the RDD, much like they would in Spark, to produce outputs (possibly to external systems) or temporary state that is fed into the next time interval.</p>
<ul>
<li><em>Timing.</em> Spark Streaming batches events based on their <em>arrival time</em>, though some systems may want to batch events based on some external <em>timestamp</em>. Spark Streaming has some configurable slack time to wait before processing a batch, but otherwise this functionality can be solved by applications.</li>
<li><em>API.</em> The D-Stream interface is very similar to that of Spark but also includes windowing, incremental aggregation, tracking, and data exporting.</li>
<li><em>Consistency.</em> Some implementations of the continuous operator model have ambiguous consistency guarantees. Some operators can run ahead of others giving an inconsistent view of the system. D-Streams design makes consistency clear. D-Streams are discretized by interval, so once an RDD for a given interval is complete, it is a consistent snapshot of the system.</li>
<li><em>Integration with batch.</em> Batch and stream processing are married by the integration of Spark Streaming into Spark. This allows users to do things like join streaming data with a static RDD or issue interactive queries to a streaming job.</li>
</ul>
<p>The Spark Streaming architecture is divided between three main components:</p>
<ol style="list-style-type: decimal">
<li>The <em>master</em> tracks lineage and schedules tasks.</li>
<li>The <em>workers</em> receive data, store partitions, and execute tasks.</li>
<li>The <em>client</em> injects data into the system.</li>
</ol>
<p>Data is either periodically read from a data store like HDFS or is sent into the system by a client. Workers run an LRU block store to manage RDD partitions and coordinate with the master which tracks which nodes have which blocks. The system employs traditional data processing optimizations and also introduces optimizations to I/O, pipelining, scheduling, etc. Moreover, since streaming computations run 24/7, Spark Streaming had to introduce master recovery. Master periodically write their state to HDFS which can be recovered by another master.</p>
  </div>

  <script type="text/javascript" src="../js/mathjax_config.js"></script>
	<script>
		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

		ga('create', 'UA-90310997-2', 'auto');
		ga('send', 'pageview');
	</script>
</body>
</html>
