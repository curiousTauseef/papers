<!DOCTYPE html>
<html>
<head>
  <title>Papers</title>
  <link href='../css/style.css' rel='stylesheet'>
  <meta name=viewport content="width=device-width, initial-scale=1">
</head>

<body>
  <div id=header>
    <a href="../">Papers</a>
  </div>
  <div id="container">
<h1 id="parallel-database-systems-the-future-of-high-performance-database-systems-1992"><a href="https://scholar.google.com/scholar?cluster=8498695891165572028">Parallel Database Systems: the Future of High Performance Database Systems (1992)</a></h1>
<p>Back in the day, like way back in the day, people thought parallel databases were never going to take off and that specialized hardware was the way of the future. They were wrong.</p>
<h2 id="parallel-database-techniques">Parallel Database Techniques</h2>
<p>The relational model permits two forms of parallelism which parallel databases take advantage of:</p>
<ol style="list-style-type: decimal">
<li><strong>Pipelined parallelism</strong> occurs when multiple operators that pipe into one another are implemented in parallel.</li>
<li><strong>Partitioned Parallelism</strong> occurs when portions of the same SQL query can be executed in parallel on different data on different machines.</li>
</ol>
<p>There are two metrics by which we typically evaluate a parallel database.</p>
<ol style="list-style-type: decimal">
<li><strong>Speedup</strong> is a measure of how much faster a fixed size task runs when we scale up the size of the database. Ideally, with <code>n</code> times the number of machines, a task will take <code>n</code> times less time.</li>
<li><strong>Scaleup</strong> is a measure of how much more load a database can handle when we scale up the size of the database. Ideally, with <code>n</code> times the number of machines, the database can handle <code>n</code> times the amount of load.</li>
</ol>
<p>There are three main overheads which prevent perfect speedup and scaleup:</p>
<ol style="list-style-type: decimal">
<li>There is a fixed <strong>startup</strong> overhead to starting multiple threads, processors, machines, etc.</li>
<li><strong>Interference</strong> between nodes contending over a shared resource (e.g. in a shared-memory database) decreases speedup and scaleup.</li>
<li>As we add more nodes, the mean completion time might decrease, but the variance increases. This leads to <strong>skew</strong> and long tails.</li>
</ol>
<h2 id="hardware-architecture-the-trend-to-shared-nothing-machines">Hardware Architecture: The Trend to Shared-Nothing Machines</h2>
<p>We are unable to build an infinitely large, infinitely fast computer. The goal of parallelization is to simulate such a machine with an infinite amount of finite machines. There are currently three approaches:</p>
<ol style="list-style-type: decimal">
<li><strong>Shared-Memory.</strong> In a shared-memory system, multiple threads or processes share a common memory and a common set of disks.</li>
<li><strong>Shared-Disks.</strong> In a shared-disk system, multiple processes do not share memory, but they share a common set of disks.</li>
<li><strong>Shared-Nothing.</strong> In a shared-nothing system, nodes don't share anything.</li>
</ol>
<p>The first two approaches require complex hardware and do not scale as well as the third. Thus, for large problems, shared-nothing architectures reign supreme.</p>
<h2 id="a-parallel-dataflow-approach-to-sql-software">A Parallel Dataflow Approach to SQL Software</h2>
<p>The relational operator model of executing SQL queries lends itself nicely to pipeline parallelism, but unfortunately, there are some limitations:</p>
<ul>
<li>Query execution plans are typically not that deep, so there isn't a boatload of parallelism to take advantage of.</li>
<li>Some operators like aggregates cannot be pipelined.</li>
<li>Some operators take significantly longer than others. This asymmetry in compute time can cause some operators to stall and wait for others.</li>
</ul>
<h2 id="data-partitioning">Data Partitioning</h2>
<p>There are a couple of ways to partition data across a number of nodes: round robin partitioning, hash partitioning, and range partitioning. Round robin partitioning is really only good if the only thing we're doing is full table scans. Hash partitioning helps spread data and avoid data skew problems but doesn't permit range queries. Range partitioning permits range queries is susceptible to data skew.</p>
<h2 id="parallelism-within-relational-operators">Parallelism within Relational Operators</h2>
<p>Many parallel database inject distribute query operators into their query plan to orchestrate data across multiple machines. The <strong>merge</strong> operator (really a union operator) merges in the results of a subquery being run on multiple nodes. The <strong>split</strong> operator takes a set of data and distributed it across multiple machines. For example, imagine joining two relations on a common attribute. The split operator might hash partition data to a set of nodes based on the join columns. These operators often implement some form of push back to avoid overloading an operator.</p>
<h2 id="state-of-the-art">State of the Art</h2>
<p>There are many state of the art (as of 1992) parallel databases including Teradata, Tandem Nonstop SQL, Gamma, Bubba, and Super Database Computer. Refer to the paper for details.</p>
<h2 id="future-work">Future Work</h2>
<p>There is a lot of future work (in 1992) in mixed OLTP/OLAP workloads, distributed query optimization, parallel programs (e.g. Spark), and online data reorganization.</p>
  </div>

  <script type="text/javascript" src="../js/mathjax_config.js"></script>
	<script>
		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

		ga('create', 'UA-90310997-2', 'auto');
		ga('send', 'pageview');
	</script>
</body>
</html>
