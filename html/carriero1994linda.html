<!DOCTYPE html>
<html>
<head>
  <title>Papers</title>
  <link href='../css/style.css' rel='stylesheet'>
  <meta name=viewport content="width=device-width, initial-scale=1">
</head>

<body>
  <div id=header>
    <a href="../">Papers</a>
  </div>
  <div id="container">
<h2 id="the-linda-alternative-to-message-passing-systems-1994"><a href="https://scholar.google.com/scholar?cluster=2449406388273902590&amp;hl=en&amp;as_sdt=0,5">The Linda alternative to message-passing systems (1994)</a></h2>
<p><strong>Summary.</strong> <em>Distributed shared memory</em> is a powerful abstraction for implementing distributed programs, but implementing the abstraction efficiently is very challenging. This led to the popularity of message passing abstractions for parallel and distributed programming which were easier to implement. Linda is a programming model and family of programming languages that does implement distributed shared memory as efficiently (or almost as efficiently) as message passing.</p>
<p>Linda's memory model revolves around a <em>tuple space</em>: a collection of tuples (pretty much a table). Users interact with the tuple space by writing programs in one of the Linda languages. For example, C-Linda programs are traditional C programs that can additionally use one of a few Linda constructs:</p>
<ul>
<li><code>out(...)</code> synchronously writes tuples into a tuple space.</li>
<li><code>eval(...)</code> concurrently evaluates its arguments and writes tuples into a tuple space asynchronously.</li>
<li><code>in(...)</code> reads and removes a single tuple from the tuple space using a tuple template: a partial tuple filled in with wildcards.</li>
<li><code>rd(...)</code> is a nondestructive version of <code>in</code>.</li>
</ul>
<p>The paper argues for the flexibility and expressiveness of Linda's memory model. It makes it easy to implement master/slave architectures where all workers can access a shared data structure. The data-centric approach allows processes to communicate by reading and writing data rather than bothering with message passing details. Tuple spaces make it easy to implement <em>static load balancing</em> in which some static domain is divided evenly between workers and <em>dynamic load balancing</em> in which the tuple space acts as a queue of requests which are read and processed by workers.</p>
<p>Linda's implementation comprises three parts:</p>
<ol style="list-style-type: decimal">
<li><em>Language-dependent compilers</em> compile out the Linda specific constructs. For example, the C-Linda compiler compiles a C-Linda compiler into pure C; the Linda constructs are compiled to function calls which eventually call into the Linda runtime.</li>
<li>The <em>link-time optimizer</em> chooses the best tuple space accessor implementations to use for the specific program.</li>
<li><p>The <em>machine-dependent run-time</em> partitions the tuple space so that each participating machine serves as both a <em>computation server</em> and a <em>tuple space server</em>. Every tuple of a particular tuple type (determined by the number of types of its constituents) is assigned to a single Linda server known as the <em>rendezvous point</em>. The runtime performs a few notable optimizations:</p>
<ul>
<li>Certain tuple types are partitioned across machines, rather than all being assigned to a single rendezvous point.</li>
<li>Certain tuple fields can be quite large in which case, they are not transfered from a machine to the rendezvous point. Instead, they are kept locally on the machine that produced them. The rendezvous point is then used as a metadata service to locate the field's location. This is similar to GFS's design.</li>
<li>Some reads are broadcasted to all nodes unsolicitedly as a form of prefetching.</li>
<li>Rendezvous nodes can be reassigned dynamically depending on the workload to place data as close as possible to the accessor.</li>
</ul></li>
</ol>
<p><strong>Commentary.</strong> The paper argues that Linda's memory model is expressive, and they support their claim by implementing a particular scientific computing style application. I disagree. I think the memory model is primitive and missing some very useful features. In particular,</p>
<ul>
<li>Only one tuple can ever be returned at a time.</li>
<li>Tuple queries are based solely on equality of individual fields. Queries such as &quot;select all tuples whose first column is greater than its third column&quot; are not supported.</li>
<li>There are no transactions. The paper also does not describe the consistency of the system.</li>
</ul>
<p>Essentially, the system is more or less a key-value store which arguably is not expressive enough for many applications. Moreover, I believe there are some implementation oversights.</p>
<ul>
<li>Data is not replicated.</li>
<li>Only certain tuple types are sharded, and skewed data distributions are not discussed.</li>
</ul>
  </div>

  <script type="text/javascript" src="../js/mathjax_config.js"></script>
	<script>
		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

		ga('create', 'UA-90310997-2', 'auto');
		ga('send', 'pageview');
	</script>
</body>
</html>
